<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Prabesh The Analyst Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">

				<!-- Intro -->
					<div id="intro">
						<h1>Prabesh The Big Data Analyst Portfolio<br />
						</h1>
						<h2>A Big Data Journey<br />
						</h2>
						<p>Big Data Analyst skilled in SQL (MySQL, PostgreSQL), Hadoop, Spark, Python (including libraries like Pandas and NumPy), and
						DataBricks. Proficient in data manipulation, analysis, and visualization using various tools and frameworks to derive
						actionable insights. <a href="https://drive.google.com/file/d/1n5DK2SVC74-O5Zf99ZDCBumxCu-7mJgK/view?usp=sharing" target="_blank">@My_RESUME</a><br />
						</p>
						<ul class="actions">
							<li><a href="#header" class="button icon solid solo fa-arrow-down scrolly">Continue</a></li>
						</ul>
					</div>

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Prabesh The Analyst</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li class="active"><a href="index.html">Big Data Insights</a></li>
							<li><a href="blogs.html">Blogs</a></li>
							<li><a href="about_me.html">About Me</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://twitter.com/Prabesh_rai567" target="_blank" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="https://www.linkedin.com/in/prabesh-rai-2593b6204/" target="_blank" class="icon brands alt fa-linkedin"><span class="label">Linkedin</span></a></li>
 							<li><a href="https://github.com/Prabesh789" target="_blank" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<!-- Featured Post -->
						<h2>Project Highlights</h2>
						<!-- Posts -->
							<section class="posts">
								<article>
									<header>
										<h2><a href="#">Data Exploration In DataBricks<br />
										</a></h2>
									</header>
									<a href="https://github.com/Prabesh789/Prabesh789-Prabesh789-PrabeshTheAnalyst-Data/blob/main/sales_dataset.ipynb"
										target="_blank" class="image fit">
										<img src="images/sales.jpg" alt=""  />
									</a>
									<p>Data Exploration of Sales Dataset in DataBricks.</p>
									<ul class="actions special">
										<li><a href="https://github.com/Prabesh789/Prabesh789-Prabesh789-PrabeshTheAnalyst-Data/blob/main/sales_dataset.ipynb" target="_blank" class="button">View Project On GitHub</a></li>
									</ul>
								</article>
								<article>
									<header>
										<h2><a href="#">Data Exploration In DataBricks<br />
										</a></h2>
									</header>
									<a href="https://github.com/Prabesh789/Prabesh789-Prabesh789-PrabeshTheAnalyst-Data/blob/main/menu_dataset.ipynb" target="_blank" class="image fit"><img src="images/menu.jpg" alt="" /></a>
									<p>Data Exploration of Menu Dataset in DataBricks.</p>
									<ul class="actions special">
										<li><a href="https://github.com/Prabesh789/Prabesh789-Prabesh789-PrabeshTheAnalyst-Data/blob/main/menu_dataset.ipynb" target="_blank" class="button">View Project On GitHub</a></li>
									</ul>
								</article>
								<article>
									<header>
										<h2><a href="#">Data analysis using PySpark and visualizations in Databricks<br />
										</a></h2>
									</header>
									<a href="https://github.com/Prabesh789/Prabesh789-Prabesh789-PrabeshTheAnalyst-Data/blob/main/c0932089%20Assignemnt%20II%2C%20Notebook%202024-03-01%2001_43_35.ipynb" target="_blank" class="image fit"><img src="images/analysis.jpg" alt="" /></a>
									<p>In this project, data analysis was conducted using PySpark and visualizations in Databricks on sales and menu datasets,
									deriving actionable insights and key performance indicators (KPIs) for informed decision-making.</p>
									<ul class="actions special">
										<li><a href="https://github.com/Prabesh789/Prabesh789-Prabesh789-PrabeshTheAnalyst-Data/blob/main/c0932089%20Assignemnt%20II%2C%20Notebook%202024-03-01%2001_43_35.ipynb" target="_blank" class="button">View Project On GitHub</a></li>
									</ul>
								</article>
								<article>
									<header>
										<h2><a href="#">MapReduce with Apache Spark: Text Processing on Databricks<br />
										</a></h2>
									</header>
									<a href="https://github.com/Prabesh789/Prabesh789-Prabesh789-PrabeshTheAnalyst-Data/blob/main/MapReduce/Assignment%20III%2C%20ApacheSpark%202024-03-15%2013_47_03.ipynb" target="_blank" class="image fit"><img src="images/mapReduce.jpg" alt="" /></a>
									<p>In this project, a MapReduce program for processing the provided text file (word_count.txt) was developed using Apache
									Spark within Databricks.</p>
									<ul class="actions special">
										<li><a href="https://github.com/Prabesh789/Prabesh789-Prabesh789-PrabeshTheAnalyst-Data/blob/main/MapReduce/Assignment%20III%2C%20ApacheSpark%202024-03-15%2013_47_03.ipynb" target="_blank" class="button">View Project On GitHub</a></li>
									</ul>
								</article>
									<article>
										<header>
											<h2><a href="#">Correlation and the relationship between different variables<br />
												</a></h2>
										</header>
										<a href="https://github.com/Prabesh789/Prabesh789-Prabesh789-PrabeshTheAnalyst-Data/blob/main/Assignment%20IV%2C%20Correlation%20and%20relationship%20between%20different%20variables%202024-04-05.ipynb"
											target="_blank" class="image fit"><img src="images/corr.png" alt="" /></a>
										<p>In this project, I utilized Apache Spark and Databricks Community Edition to perform correlation analysis on the Iris
										dataset. The primary objectives were to calculate correlations between different variables using both DataFrame API and
										RDD, and then visualize the correlation matrix as a heatmap.</p>
										<ul class="actions special">
											<li><a href="https://github.com/Prabesh789/Prabesh789-Prabesh789-PrabeshTheAnalyst-Data/blob/main/Assignment%20IV%2C%20Correlation%20and%20relationship%20between%20different%20variables%202024-04-05.ipynb"
													target="_blank" class="button">View Project On GitHub</a></li>
										</ul>
									</article>
							</section>
							<div class="content">
								<h2>Big Data Insights</h2>
								<div style="text-align: left;">
									<small style="font-size: 80%;">
										Welcome to <strong>'Big Data Insights.</strong>' Through a collection of projects and critical analyses, I
										offer a nuanced exploration of
										the multifaceted world of big data. Each project showcases practical applications of big data technologies,
										highlighting
										my skills in data analysis, visualization, and problem-solving. Additionally, my critical analyses of
										research papers
										provide deeper insights into key concepts and emerging trends within the field. By synthesizing practical
										experience
										with scholarly inquiry, I aim to provide valuable insights that contribute to the ongoing discourse
										surrounding big data
										and its implications for various industries and domains. <br>
									</small>
									<strong>BIG DATA </strong>
									<div style="text-align: left;">
									<small style="font-size: 80%;">
										Big data refers to extremely large and complex datasets that cannot be effectively managed, processed, or analyzed using
										traditional data processing tools and techniques. These datasets typically exhibit the characteristics of volume,
										velocity, and variety, requiring specialized tools and methodologies to extract meaningful insights. By harnessing the
										power of big data analytics, organizations can uncover valuable insights, identify trends, and make data-driven
										decisions to gain a competitive edge in their respective domains.<br>
									</small>
								</div>
								<strong>KEY CONCEPTS AND TECHNOLOGY THROUGH MY PROJECTS</strong>
								<div style="text-align: left;">
									<small style="font-size: 80%;">
										<strong>1. Hadoop HDFS </strong>
										<p>The project involves performing tasks related to directory creation, file manipulation, and Hadoop Distributed File
										System (HDFS) management in the ITVersity lab. The project consists of several steps, including creating a directory
										using my first and last name (pRai), writing and executing a Python script using Vim, navigating the Hadoop directory using
										commands like $hdfs fs or $hadoop dfs, and checking file permissions. Additionally, I was required to analyze the
										configuration of HDFS and calculate the number of blocks created and the size of each block for a file of a specific
										size.</p>
										
										<p>About Project: <br>
										<strong>a. Create a directory by your first & last name:</strong> Create a directory with the specified naming convention. <br>
										<strong>b. Open Vim:</strong> <br>
										<strong>c. Write a Python file and save it with .py extension:</strong> Utilized Vim to write a Python script and saved it with the .py
											   extension. <br>
										<strong>d. Execute your Python code:</strong> Executed the Python code within the Vim environment. <br>
										<strong>e. Navigate the Hadoop directory using $hdfs fs or $hadoop dfs command:</strong> Utilized Hadoop commands to navigate the Hadoop
											   directory. <br>
										<strong>f. Check for the file permissions:</strong> Verified file permissions using appropriate commands. <br>
										<strong>SCREENSHOTS</strong> <br>
										<strong>Creating a Directory</strong> <br>
										<img src="images/img1.png" alt="Screenshot" "> <br>
										<strong>Creating a Python file and save it with .py extension</strong> <br>
										<img src="images/img2.png" alt="Screenshot" "> <br>
										<strong>Navigating Hadoop directory using hdfs dfs command</strong> <br>
										<img src="images/img3.png" alt="Screenshot" "> <br>
										</p>
									</small>
									<hr>
									<small style="font-size: 80%;">
										<strong>1. MapReduce in Hadoop </strong>
										<p>In this project, a fundamental MapReduce task was undertaken using Python to analyze the content of a text file within
										the ITVersity lab environment. The objective was to gain practical experience in implementing the MapReduce paradigm and
										performing basic data analysis tasks.</p>
									
										<p>About Project: <br>
											<strong>a. Create an .txt file:</strong> Created a text file named assignment2.txt to serve as input data for the MapReduce task. <br>
											<strong>b. Create a mapper.py program:</strong> Developed a Python script named mapper.py to serve as the Mapper function in the MapReduce process. The Mapper function
											extracts relevant information from the input data. <br>
											<strong>c. Create a reducer.py file:</strong> Developed a Python script named reducer.py to serve as the Reducer function in the MapReduce process. The Reducer
											function aggregates and processes the output generated by the Mapper function. <br>
											<strong>d. Perform a Mapper task by passing the file to the mapper.py:</strong> Executed the Mapper task by passing the assignment2.txt file to the mapper.py script, which generated intermediate
											key-value pairs. <br>
											<strong>e. Perform a Reducer task by passing the file to the reducer.py:</strong> Executed the Reducer task by passing the output generated by the Mapper task to the reducer.py script, which produced
											the final output based on the MapReduce computation. <br>
											<strong>SCREENSHOTS</strong> <br>
											<strong>Creating .txt file</strong> <br>
											<img src="images/img4.png" alt="Screenshot" "> <br>
											<strong>Creating mapper.py program</strong> <br>
											<img src=" images/img5.png" alt="Screenshot" "> <br>
											<strong>Perform a Mapper task by passing the file to the mapper.py;</strong> <br>
											<img src=" images/img6.png" alt="Screenshot" "> <br>
											<strong>Creating reducer.py Program</strong> <br>
											<img src=" images/img7.png" alt="Screenshot" "> <br>
											<strong>Perform a Reducer task by passing the file to the reduce.py, which takes two arguments;</strong> <br>
											<img src=" images/img8.png" alt="Screenshot" "> <br>
										</p>
										</small>
																			<hr>
									<small style="font-size: 80%;">
										<strong>2. MapReduce in Hadoop </strong>
										<p>In this project, a fundamental MapReduce task was undertaken using Python to analyze the content of a text file within
										the ITVersity lab environment. The objective was to gain practical experience in implementing the MapReduce paradigm and
										performing basic data analysis tasks.</p>
									
										<p>About Project: <br>
											<strong>a. Create an .txt file:</strong> Created a text file named assignment2.txt to serve as input data for the MapReduce task. <br>
											<strong>b. Create a mapper.py program:</strong> Developed a Python script named mapper.py to serve as the Mapper function in the MapReduce process. The Mapper function
											extracts relevant information from the input data. <br>
											<strong>c. Create a reducer.py file:</strong> Developed a Python script named reducer.py to serve as the Reducer function in the MapReduce process. The Reducer
											function aggregates and processes the output generated by the Mapper function. <br>
											<strong>d. Perform a Mapper task by passing the file to the mapper.py:</strong> Executed the Mapper task by passing the assignment2.txt file to the mapper.py script, which generated intermediate
											key-value pairs. <br>
											<strong>e. Perform a Reducer task by passing the file to the reducer.py:</strong> Executed the Reducer task by passing the output generated by the Mapper task to the reducer.py script, which produced
											the final output based on the MapReduce computation. <br>
											<strong>SCREENSHOTS</strong> <br>
											<strong>Creating .txt file</strong> <br>
											<img src="images/img4.png" alt="Screenshot" "> <br>
											<strong>Creating mapper.py program</strong> <br>
											<img src=" images/img5.png" alt="Screenshot" "> <br>
											<strong>Perform a Mapper task by passing the file to the mapper.py;</strong> <br>
											<img src=" images/img6.png" alt="Screenshot" "> <br>
											<strong>Creating reducer.py Program</strong> <br>
											<img src=" images/img7.png" alt="Screenshot" "> <br>
											<strong>Perform a Reducer task by passing the file to the reduce.py, which takes two arguments;</strong> <br>
											<img src=" images/img8.png" alt="Screenshot" "> <br>
										</p>
										</small>
									<hr>
									<small style="font-size: 80%;">
										<strong>3. Data Analysis & Visualization Using PySpark in Databricks</strong>
										<p>This project entailed the creation of a schema structure for two provided CSV files, namely menu.csv and sales.csv,
										followed by the development of insightful visualizations for key performance indicators (KPIs) extracted from the
										dataset.</p>
									
										<p>About Project: <br>
											<strong>DataSet</strong><br>
											<a href="https://drive.google.com/file/d/103HCXH0f4_Eiab0Vg_lrMMrOtTvEji2R/view?usp=sharing" target="_blank">
												<strong>"MENU Data" (VIEW menu.csv)</strong></a> <br>
											<a href="https://drive.google.com/file/d/1RjS-eE4YB63VXssub7xVWuRvYt10TPjO/view?usp=sharing" target="_blank">
												<strong>"Sales Data" (VIEW sales.csv)</strong> </a> <br>

											
											<strong>a. Schema Structuring:</strong> <br>
											- Utilized data structuring techniques to design a schema for the provided CSV files (menu.csv and sales.csv). <br>
											- Established appropriate data types and relationships to ensure data integrity and facilitate effective analysis. <br>
											<strong>b. Visualization Development:</strong>  <br>
											- <strong>Total Amount Spent on Each Food Category:</strong> Developed visual representations showcasing the total expenditure on various
											food categories, aiding in understanding customer preferences and sales distribution. <br>
											- <strong> Total Amount Spent by Each Customer:</strong> Created visualizations illustrating individual customer spending patterns,
											facilitating personalized marketing strategies and customer relationship management. <br>
											- <strong> Total Amount of Sales for Each Month:</strong> Generated visual insights into monthly sales volumes, facilitating the
											identification of seasonal trends and informing inventory management decisions. <br>
											- <strong> Yearly and Quarterly Sales:</strong> Analyzed sales data to discern annual and quarterly performance trends, providing strategic
											planning and forecasting insights. <br>
											- <strong> Top Ordered Food Items:</strong> Identified the most frequently ordered items through visual analysis, informing menu
											optimization strategies and inventory stocking decisions. <br>
											- <strong> Total Sales by Each Country:</strong> Visualized sales data by country to assess regional performance and identify potential
											market expansion opportunities.
											Through this project, I enhanced my proficiency in data structuring and visualization techniques. By leveraging the
											schema structure and developing insightful visualizations, I gained valuable insights into sales trends, customer
											behavior, and market dynamics, empowering data-driven decision-making processes. <br>

											<strong>SCREENSHOTS</strong> <br>
											<strong>Schema for Menu Data</strong> <br>
											<img src="images/img9.png" alt="Screenshot" "> <br>
											<strong>Schema for Sales Data</strong> <br>
											<img src="images/img10.png" alt="Screenshot" "> <br>
											<strong>Joining the Sales and Menu data (Preparation for data visualization)</strong> <br>
											<img src="images/img11.png" alt="Screenshot" "> <br>
											<strong>Total Amount spent by each food category and Visualization</strong> <br>
											<img src="images/img12.png" alt="Screenshot" "> <br>
											<img src="images/img13.png" alt="Screenshot" "> <br>
											<strong>Total Amount spent by each customer and Visualization</strong> <br>
											<img src="images/img14.png" alt="Screenshot" "> <br>
											<img src=" images/img15.png" alt="Screenshot" "> <br>
											<strong>Total Amount of sales for each month and Visualization</strong> <br>
											<img src="images/img16.png" alt="Screenshot" "> <br>
											<img src=" images/img17.png" alt="Screenshot" "> <br>
											<strong>Total Amount of sales for Yearly sales and Visualization</strong> <br>
											<img src="images/img18.png" alt="Screenshot" "> <br>
											<img src=" images/img19.png" alt="Screenshot" "> <br>
											<strong>Total Amount of sales for quarterly sales and Visualization</strong> <br>
											<img src="images/img20.png" alt="Screenshot" "> <br>
											<img src=" images/img21.png" alt="Screenshot" "> <br>
											<strong>The top-ordered food items</strong> <br>
											<img src="images/img22.png" alt="Screenshot" "> <br>
											<img src=" images/img23.png" alt="Screenshot" "> <br>
											<strong>The total sales by each country</strong> <br>
											<img src="images/img24.png" alt="Screenshot" "> <br>
											<img src=" images/img25.png" alt="Screenshot" "> <br>
									</small>
										<hr>
										<small style="font-size: 80%;">
											<strong>4. MapReduce Using Apache Spark </strong>
											<p>This project involved creating a MapReduce program using Apache Spark within a Databricks notebook to analyze the
											content of a given text file 
											<a href="https://drive.google.com/file/d/1fzJKRfKiDpYmqNsF4IsyAq1muithAwIS/view?usp=sharing" target="_blank">
												<strong>(wordcount.txt)</strong></a>. The objective was to implement the MapReduce paradigm to process and
											analyze the text data efficiently.</p> 

											<p>
												Through this project, I gained practical experience in implementing the MapReduce paradigm using Apache Spark within the
												Databricks notebook environment. By following the specified steps and leveraging Spark's distributed computing
												capabilities, I was able to efficiently process and analyze text data, demonstrating proficiency in big data analytics
												and distributed computing techniques.
											</p>
										
											<p>About Project: <br>
												<strong>a. Loading Text File and Assigning RDD:</strong> <br>
												- Load the text file wordcount.txt from the local file system into Apache Spark, assigning it to a Resilient Distributed
												Dataset (RDD) variable. <br>
												<strong>b. Retrieving RDD Contents as Local Collection:</strong><br>
												- Retrieved the RDD contents as a local collection by using the rdd.collect() function to facilitate further processing. <br>
												<strong>c. Mapping Elements to Zero or More Others:</strong> <br>
												- Map each element in the RDD to zero or more other elements based on specified criteria or operations.<br>
												<strong>d. Applying Lambda Function:</strong> <br>
												- Pass each element through a lambda function to perform individual processing steps or transformations. <br>
												<strong>e. Aggregating Data with Reduce Function:</strong> <br>
												- Used an associative reduce function to aggregate data corresponding to a key, consolidating and summarizing information
												as needed. <br>
												<strong>f. Writing Elements to a Text File:</strong> <br>
												- Write the results to a new text file using the saveAsTextFile() function, saving the output for further analysis or
												presentation. <br>
												<strong>SCREENSHOTS</strong> <br>
												<strong>Dataset</strong> <br>
												<img src="images/img26.png" alt="Screenshot" "> <br>
												<strong>Loading data into Databricks</strong> <br>
												<img src="images/img27.png" alt="Screenshot" "> <br>
												<img src="images/img28.png" alt="Screenshot" "> <br>
												<img src="images/img29.png" alt="Screenshot" "> <br>
												<img src="images/img30.png" alt="Screenshot" "> <br>
												<img src="images/img31.png" alt="Screenshot" "> <br>
												</p>
									</small>
									<hr>
									</small>
									<small style="font-size: 80%;">
										<strong>5. Correlation Analysis Using Iris Flower Dataset in Apache Spark </strong>
										<p>A Databricks notebook was employed for statistical analysis of the IRIS flower dataset using Apache Spark. The aim was
										to investigate correlations among various variables by generating a heatmap through a correlation matrix.
										</p>
									
										DATASET
										<p><a href="https://drive.google.com/file/d/1Kted4vna2gttvkEHGyTrkI4luGs-Oo-N/view?usp=sharing" target="_blank">
											<strong>data (Iris DATASET.csv)</strong></a></p>
									
										<p>About Project: <br>
											<strong>a. Importing Required Library:</strong> <br>
											- The IRIS dataset is uploaded to the Databricks File System Target Directory with the URL /FileStore/tables/Iris.csv.											
											Following that, essential libraries such as SparkSession, functions for correlation computation, and visualization
											libraries are imported. SparkSession is imported to the Databricks using the "from" and "import" functions. <br>
											<img src="images/img32.png" alt="Screenshot" "> <br>
											<strong>b. Correlation using DataFrame API:</strong> <br>
											- Through the loaded DataFrame, correlations between different columns, representing variables within the IRIS dataset,
											are computed using Spark's DataFrame API.
											​<br>
											This method streamlines the process, enabling direct computation of correlations between columns.
											​<br>
											The correlation analysis highlights the relationship between variables like SepalLenghtCm and PetalLenghtCm of an Iris
											Flower. <br>
											<img src="images/img33.png" alt="Screenshot" "> <br>
											The correlation analysis using DataFrame API shows a strong positive relationship between the
											SepalLengthCm and PetalLengthCm variables in the Iris dataset. With a correlation coefficient of
											approximately 0.87, we observe a robust linear association between these two attributes. This correlation
											coefficient indicates that as the length of the sepals increases, there is a corresponding increase in the size
											of the petals, and vice versa. The scatter plot visualization further reinforces this finding, as the data
											points cluster around a positively sloped line. This strong positive correlation implies that changes in
											SepalLengthCm are closely related to changes in PetalLengthCm, providing valuable insights into the
											interdependence of these two characteristics within the Iris dataset. <br>

											<strong>c. Correlation using RDD:</strong> <br>
											- In this step, the Iris Dataset transformed into an RDD (Resilient Distributed Dataset), and the Statistics.corr()
											function from the pyspark.mllib.stat module is employed to calculate the correlation. <br>
											This approach proves beneficial for handling more intricate computations or situations where the DataFrame API alone may
											not be adequate. <br>
											<img src="images/img34.png" alt="Screenshot" "> <br>
											<img src="images/img35.png" alt="Screenshot" "> <br>
											From the above the correlation matrix presents several key relationships among the variables in the Iris
											dataset. Firstly, SepalLengthCm exhibits a strong positive correlation with PetalLengthCm (correlation
											coefficient = 0.871754) and PetalWidthCm (correlation coefficient = 0.817954). This shows that as the
											length of sepals increases, there is a corresponding increase in the length and width of petals. Conversely,
											SepalWidthCm shows a weak negative correlation with both SepalLengthCm (correlation coefficient =
											-0.109369) and PetalLengthCm (correlation coefficient = -0.420516), implying a slight decrease in sepal
											width as sepal and petal lengths increase. Secondly, SepalWidthCm and PetalWidthCm demonstrate a
											moderate negative correlation (correlation coefficient = -0.356544), indicating that as the width of sepals
											increases, the width of petals tends to decrease. Finally, the correlation between PetalLengthCm and
											PetalWidthCm is notably strong (correlation coefficient = 0.962757), highlighting a robust positive
											relationship where an increase in petal length corresponds closely with an increase in petal width. These
											correlation insights offer a valuable understanding of the interdependencies and associations between
											different attributes of the Iris dataset. <br>

											<strong>d. Correlation Heat Map using Correlation Matrix:</strong> <br>
											- After obtaining the correlation matrices from both DataFrame API and RDD computations, they are visualized as a heatmap
											to better understand the relationships between variables. <br>
											Heatmaps provide a graphical representation of correlation matrices, where colors indicate the strength and direction of
											correlations. <br>
											<img src="images/img36.png" alt="Screenshot" "> <br>
											From the above figure, correlation values range from -0.4 to 1, with red indicating positive correlations
											and blue indicating negative correlations.	
										</p>
									</small>
									<hr>
									# TODO
								</div>
							</div>
					</div>
					
				<!-- Footer -->
					<!-- Footer -->
					<footer id="footer">
						<section>
							<form id="contactForm" method="post" action="#">
								<div class="fields">
									<div class="field">
										<label for="name">Name</label>
										<input type="text" name="name" id="name" />
									</div>
									<div class="field">
										<label for="email">Email</label>
										<input type="text" name="email" id="email" />
									</div>
									<div class="field">
										<label for="message">Message</label>
										<textarea name="message" id="message" rows="3"></textarea>
									</div>
								</div>
								<ul class="actions">
									<li><button type="button" id="sendMessage">Send Message</button></li>
								</ul>
							</form>
						</section>
						<section class="split contact">
							<section class="alt">
								<h3>Address</h3>
								<p>2503 Clementine Blvd<br />
									Ottawa, Ontario Canada.
								</p>
							</section>
							<section>
								<h3>Phone</h3>
								<p><a href="#">+1 (343) 543-5098</a></p>
							</section>
							<section>
								<h3>Email</h3>
								<p><a href="#">raiprabesh775@gmail.com</a></p>
							</section>
							<section>
								<h3>Social</h3>
								<ul class="icons alt">
									<li><a href="https://twitter.com/Prabesh_rai567" target="_blank"
											class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="https://github.com/Prabesh789" target="_blank" class="icon brands alt fa-github"><span
												class="label">GitHub</span></a></li>
									<li><a href="https://www.linkedin.com/in/prabesh-rai-2593b6204/" target="_blank"
											class="icon brands alt fa-linkedin"><span class="label">Linkedin</span></a></li>
								</ul>
							</section>
						</section>
					</footer>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; 2024</li><li>Design:  Prabesh Rai</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
			<script src="assets/js/footer.js"></script>

	</body>
</html>